{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T12:49:57.513722Z",
     "start_time": "2024-08-22T12:49:57.142150Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T12:55:38.830215Z",
     "start_time": "2024-08-22T12:55:37.576005Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the clustered data\n",
    "df_labeled = pd.read_parquet('../../data/processed/clustered_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T13:05:06.220318Z",
     "start_time": "2024-08-22T13:05:05.783217Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract clusters and true labels\n",
    "clusters = df_labeled['cluster'].to_numpy()\n",
    "# Remove the cluster column to get the feature data\n",
    "feature_columns = df_labeled.drop(columns=['cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 460509 entries, 0 to 460508\n",
      "Data columns (total 17 columns):\n",
      " #   Column                              Non-Null Count   Dtype              \n",
      "---  ------                              --------------   -----              \n",
      " 0   id_prenotazione                     460509 non-null  object             \n",
      " 1   id_paziente                         460509 non-null  object             \n",
      " 2   data_nascita                        460509 non-null  datetime64[ns, UTC]\n",
      " 3   sesso                               460509 non-null  object             \n",
      " 4   regione_residenza                   460509 non-null  object             \n",
      " 5   tipologia_servizio                  460509 non-null  object             \n",
      " 6   descrizione_attivita                460509 non-null  object             \n",
      " 7   data_contatto                       460509 non-null  object             \n",
      " 8   tipologia_struttura_erogazione      460509 non-null  object             \n",
      " 9   id_professionista_sanitario         460509 non-null  object             \n",
      " 10  tipologia_professionista_sanitario  460509 non-null  object             \n",
      " 11  data_erogazione                     460509 non-null  datetime64[ns, UTC]\n",
      " 12  durata_erogazione_sec               460509 non-null  int64              \n",
      " 13  fascia_eta                          460509 non-null  object             \n",
      " 14  anno                                460509 non-null  int32              \n",
      " 15  quadrimestre                        460509 non-null  int32              \n",
      " 16  incremento_teleassistenze           460509 non-null  object             \n",
      "dtypes: datetime64[ns, UTC](2), int32(2), int64(1), object(12)\n",
      "memory usage: 56.2+ MB\n"
     ]
    }
   ],
   "source": [
    "feature_columns.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T13:09:38.055877Z",
     "start_time": "2024-08-22T13:09:34.773708Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NOTE this is not needed, cause these columns are note used in the clustering\n",
    "\n",
    "# Convert the datetime columns to Unix timestamp\n",
    "feature_columns['data_erogazione'] = feature_columns['data_erogazione'].apply(lambda x: x.timestamp() if pd.notnull(x) else np.nan)\n",
    "feature_columns['data_nascita'] = feature_columns['data_nascita'].apply(lambda x: x.timestamp() if pd.notnull(x) else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T13:09:52.287163Z",
     "start_time": "2024-08-22T13:09:46.919532Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert non-numeric columns to numeric using LabelEncoder\n",
    "for column in feature_columns.columns:\n",
    "    if feature_columns[column].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        feature_columns[column] = le.fit_transform(feature_columns[column])\n",
    "        \n",
    "# NOTE Sarebbe meglio usare OneHotEncoder ma avendo un dataset molto grande non posso permettermi di fare one hot encoding in quanto la memoria non basta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supponendo che X sia il tuo dataframe o array di feature\n",
    "scaler = StandardScaler()\n",
    "X_standardized = scaler.fit_transform(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0         1         2         3         4    5         6         7   \\\n",
      "0  0.171870 -0.246634 -0.010057  1.088312  0.250476  0.0 -0.308295 -1.732474   \n",
      "1  1.478943 -0.173594 -0.340067 -0.918854  1.284751  0.0  0.515240 -1.732413   \n",
      "2 -1.073324 -0.454155  0.237424  1.088312 -0.956180  0.0  0.412298 -1.732376   \n",
      "3  1.308585  0.854205 -0.511492 -0.918854 -1.128559  0.0  1.184363 -1.732368   \n",
      "4  1.477928  1.289516 -0.678198  1.088312 -1.645697  0.0  0.412298 -1.732285   \n",
      "\n",
      "         8         9         10        11        12        13        14  \\\n",
      "0 -1.828384 -0.006025 -0.086304 -1.983333  0.624216 -0.037041 -1.578466   \n",
      "1 -1.416034 -1.203662 -0.086304 -1.991300 -0.286234  0.450240 -1.578466   \n",
      "2  0.645713  0.330431 -1.538514 -1.986431 -0.931505 -0.037041 -1.578466   \n",
      "3 -1.828384  1.136801  1.849977 -1.991742 -0.220823  0.450240 -1.578466   \n",
      "4  0.645713 -0.895148 -1.538514 -1.980234  0.778020  0.937521 -1.578466   \n",
      "\n",
      "         15        16  \n",
      "0 -1.409541 -1.088845  \n",
      "1 -1.409541 -1.088845  \n",
      "2 -1.409541 -1.088845  \n",
      "3 -1.409541 -1.088845  \n",
      "4 -1.409541 -1.088845  \n"
     ]
    }
   ],
   "source": [
    "X_standardized_df = pd.DataFrame(X_standardized)\n",
    "print(X_standardized_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T13:11:15.685310Z",
     "start_time": "2024-08-22T13:11:15.671369Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to calculate and normalize Silhouette Score\n",
    "def calculate_silhouette_score(features , clusters):\n",
    "    # Calculate the silhouette scores for each sample\n",
    "    silhouette_vals = silhouette_samples(features, clusters)\n",
    "\n",
    "    # Calculate the mean silhouette score\n",
    "    mean_silhouette = silhouette_score(features, clusters)\n",
    "\n",
    "    # Normalize the silhouette scores to a range between 0 and 1\n",
    "    normalized_silhouette_vals = (silhouette_vals - silhouette_vals.min()) / (silhouette_vals.max() - silhouette_vals.min())\n",
    "    normalized_mean_silhouette = (mean_silhouette - silhouette_vals.min()) / (silhouette_vals.max() - silhouette_vals.min())\n",
    "\n",
    "    return normalized_mean_silhouette, normalized_silhouette_vals, mean_silhouette, silhouette_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-22T13:11:16.066939Z"
    },
    "is_executing": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Calculate the normalized silhouette values\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m normalized_mean_silhouette, normalized_silhouette_vals, mean_silhouette, silhouette_vals \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_silhouette_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_standardized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclusters\u001b[49m\u001b[43m)\u001b[49m  \n",
      "Cell \u001b[0;32mIn[17], line 4\u001b[0m, in \u001b[0;36mcalculate_silhouette_score\u001b[0;34m(features, clusters)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_silhouette_score\u001b[39m(features , clusters):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Calculate the silhouette scores for each sample\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     silhouette_vals \u001b[38;5;241m=\u001b[39m \u001b[43msilhouette_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclusters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Calculate the mean silhouette score\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     mean_silhouette \u001b[38;5;241m=\u001b[39m silhouette_score(features, clusters)\n",
      "File \u001b[0;32m~/Desktop/campus bio iscrizione/ Magistrale/FIA/Teleassistance-Supervised-Clustering/venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/campus bio iscrizione/ Magistrale/FIA/Teleassistance-Supervised-Clustering/venv/lib/python3.10/site-packages/sklearn/metrics/cluster/_unsupervised.py:305\u001b[0m, in \u001b[0;36msilhouette_samples\u001b[0;34m(X, labels, metric, **kwds)\u001b[0m\n\u001b[1;32m    301\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m metric\n\u001b[1;32m    302\u001b[0m reduce_func \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(\n\u001b[1;32m    303\u001b[0m     _silhouette_reduce, labels\u001b[38;5;241m=\u001b[39mlabels, label_freqs\u001b[38;5;241m=\u001b[39mlabel_freqs\n\u001b[1;32m    304\u001b[0m )\n\u001b[0;32m--> 305\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpairwise_distances_chunked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduce_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m intra_clust_dists, inter_clust_dists \u001b[38;5;241m=\u001b[39m results\n\u001b[1;32m    307\u001b[0m intra_clust_dists \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(intra_clust_dists)\n",
      "File \u001b[0;32m~/Desktop/campus bio iscrizione/ Magistrale/FIA/Teleassistance-Supervised-Clustering/venv/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:2181\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   2179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2180\u001b[0m     chunk_size \u001b[38;5;241m=\u001b[39m D_chunk\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 2181\u001b[0m     D_chunk \u001b[38;5;241m=\u001b[39m \u001b[43mreduce_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mD_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2182\u001b[0m     _check_chunk_size(D_chunk, chunk_size)\n\u001b[1;32m   2183\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m D_chunk\n",
      "File \u001b[0;32m~/Desktop/campus bio iscrizione/ Magistrale/FIA/Teleassistance-Supervised-Clustering/venv/lib/python3.10/site-packages/sklearn/metrics/cluster/_unsupervised.py:182\u001b[0m, in \u001b[0;36m_silhouette_reduce\u001b[0;34m(D_chunk, start, labels, label_freqs)\u001b[0m\n\u001b[1;32m    180\u001b[0m         sample_weights \u001b[38;5;241m=\u001b[39m D_chunk[i]\n\u001b[1;32m    181\u001b[0m         sample_labels \u001b[38;5;241m=\u001b[39m labels\n\u001b[0;32m--> 182\u001b[0m         cluster_distances[i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbincount\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m            \u001b[49m\u001b[43msample_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminlength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlabel_freqs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# intra_index selects intra-cluster distances within cluster_distances\u001b[39;00m\n\u001b[1;32m    187\u001b[0m end \u001b[38;5;241m=\u001b[39m start \u001b[38;5;241m+\u001b[39m n_chunk_samples\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Calculate the normalized silhouette values\n",
    "normalized_mean_silhouette, normalized_silhouette_vals, mean_silhouette, silhouette_vals = calculate_silhouette_score(X_standardized_df, clusters)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results\n",
    "print('Normalized Mean Silhouette Score:', normalized_mean_silhouette)\n",
    "print('Normalized Silhouette Values:', normalized_silhouette_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the silhouette values for each sample\n",
    "plt.figure(figsize=(10, 7))\n",
    "y_lower = 10\n",
    "for i in np.unique(clusters):\n",
    "    ith_cluster_silhouette_vals = silhouette_vals[clusters == i]\n",
    "    ith_cluster_silhouette_vals.sort()\n",
    "    size_cluster_i = ith_cluster_silhouette_vals.shape[0]\n",
    "    y_upper = y_lower + size_cluster_i\n",
    "\n",
    "    plt.fill_betweenx(np.arange(y_lower, y_upper), 0, ith_cluster_silhouette_vals, alpha=0.7)\n",
    "    plt.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "    y_lower = y_upper + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Silhouette plot for the various clusters')\n",
    "plt.xlabel('Silhouette coefficient values')\n",
    "plt.ylabel('Cluster label')\n",
    "plt.axvline(x=mean_silhouette, color=\"red\", linestyle=\"--\")\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
